{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 5 Supplementary Notebook\n",
    "\n",
    "## DSC 40A, Summer 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell sets up the necessary imports â€“ don't worry too much about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "set_matplotlib_formats(\"svg\")\n",
    "\n",
    "pd.options.plotting.backend = \"plotly\"\n",
    "\n",
    "# DSC 80 preferred styles\n",
    "pio.templates[\"dsc80\"] = go.layout.Template(\n",
    "    layout=dict(\n",
    "        margin=dict(l=30, r=30, t=30, b=30),\n",
    "        autosize=True,\n",
    "        xaxis=dict(showgrid=True),\n",
    "        yaxis=dict(showgrid=True),\n",
    "        title=dict(x=0.5, xanchor=\"center\"),\n",
    "    )\n",
    ")\n",
    "pio.templates.default = \"simple_white+dsc80\"\n",
    "\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load in the commute times dataset as a `pandas` DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/commute-times.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many columns in here, but the only ones we're interested in for now are `'departure_hour'` and `'minutes'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['departure_hour', 'minutes']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pio.renderers.default = 'plotly_mimetype+notebook' # If the plot doesn't load for you, run this first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(df,\n",
    "           x='departure_hour',\n",
    "           y='minutes',\n",
    "           size=np.ones(len(df)) * 50,\n",
    "           size_max=8)\n",
    "fig.update_xaxes(title='Home Departure Time (AM)')\n",
    "fig.update_yaxes(title='Minutes to School')\n",
    "fig.update_layout(title='Commuting Time vs. Home Departure Time')\n",
    "fig.update_layout(width=700)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation\n",
    "\n",
    "$$\\begin{align*} r &= \\text{the average of the product of $x$ and $y$, when both are in standard units} \\\\ &= \\frac{1}{n} \\sum_{i = 1}^n \\left( \\frac{x_i - \\bar{x}}{\\sigma_x} \\right) \\left( \\frac{y_i - \\bar{y}}{\\sigma_y} \\right)  \\end{align*}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(x, y):\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    x_su = (x - np.mean(x)) / np.std(x, ddof=0) # make sure we divide by n, not n-1\n",
    "    y_su = (y - np.mean(y)) / np.std(y, ddof=0)\n",
    "    \n",
    "    return np.mean(x_su * y_su)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = df['departure_hour'] # How we access columns in pandas.\n",
    "ys = df['minutes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation(xs, ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Symmetric!\n",
    "correlation(ys, xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doesn't change if we multiply x or y by constants!\n",
    "correlation(xs * 1000, ys * 545)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DataFrames in pandas have a built-in correlation method\n",
    "df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing $w_0^*$ and $w_1^*$\n",
    "\n",
    "Recall, the formulas for the optimal intercept and slope are\n",
    "\n",
    "$$w_1^* = r \\frac{\\sigma_y}{\\sigma_x}$$\n",
    "\n",
    "$$w_0^* = \\bar{y} - w_1^* \\bar{x}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slope(x, y):\n",
    "    return correlation(x, y) * np.std(y) / np.std(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intercept(x, y):\n",
    "    return np.mean(y) - slope(x, y) * np.mean(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w0_star = intercept(xs, ys)\n",
    "w1_star = slope(xs, ys)\n",
    "\n",
    "# Just fancy printing â€“ ignore these next two lines.\n",
    "rule_string = ('$$\\\\text{Predicted Commute Time (in Minutes)} = ' + \n",
    "               f'{round(w0_star, 2)} + {round(w1_star, 2)}' + \n",
    "               '\\cdot \\\\left( \\\\text{Departure Hour} \\\\right)$$')\n",
    "display(HTML(f'<h4>The best linear predictor for this dataset is</h4><br><center>{rule_string}</center>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hline = px.line(x=[5.5, 11.5], y=[97.405, 48.265]).update_traces(line={'color': 'red', 'width': 4})\n",
    "fline1 = go.Figure(fig.data + hline.data)\n",
    "fline1.update_xaxes(title='Home Departure Time (AM)')\n",
    "fline1.update_yaxes(title='Minutes to School')\n",
    "fline1.update_layout(title='<span style=\"color:red\">Predicted Commute Time</span> = 142.45 - 8.19 * Departure Hour')\n",
    "fline1.update_layout(width=700, margin={'t': 60})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have $w_0^*$ and $w_1^*$, we can use them to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_commute(x_new):\n",
    "    return w0_star + w1_star * x_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_commute(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_commute(7.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does this make sense?\n",
    "predict_commute(4.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What does $R_{\\text{sq}}(w_0, w_1)$ look like?\n",
    "\n",
    "Let's draw a plot of $R_{\\text{sq}}(w_0, w_1)$, the empirical risk that we're trying to minimize.\n",
    "- When we only had a single parameter, $h$, $R(h)$ was in 2D.\n",
    "    - One axis for $h$, one axis for $R(h)$.\n",
    "- Now that we have two parameters, $w_0$ and $w_1$, $R(w_0, w_1)$ will be in 3D!\n",
    "    - One axis for $w_0$, one axis for $w_1$, one axis for $R(w_0, w_1)$.\n",
    "    - The bottom plane consists of all possible combinations of slope and intercept.\n",
    "    - The height of the function above any pair of points on the bottom plane represents the MSE for that combination of slope and intercept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y_actual, y_pred):\n",
    "    return np.mean((y_actual - y_pred)**2)\n",
    "\n",
    "def mse_for_departure_model(w):\n",
    "    w0, w1 = w\n",
    "    return mse(df['minutes'], w0 + w1 * df['departure_hour'])\n",
    "\n",
    "num_points = 50 # increase for better resolution, but it will run more slowly. \n",
    "\n",
    "# if (num_points <= 100):\n",
    "\n",
    "uvalues = np.linspace(90, 190, num_points)\n",
    "vvalues = np.linspace(-13, -3, num_points)\n",
    "(u,v) = np.meshgrid(uvalues, vvalues)\n",
    "thetas = np.vstack((u.flatten(),v.flatten()))\n",
    "\n",
    "MSE = np.array([mse_for_departure_model(t) for t in thetas.T])\n",
    "\n",
    "loss_surface = go.Surface(x=u, y=v, z=np.reshape(MSE, u.shape))\n",
    "\n",
    "# opt_point = go.Scatter3d(x = [ahat], y = [bhat], z = [mse_for_height_model((ahat, bhat))],\n",
    "#             mode = 'markers', name = 'optimal parameters',\n",
    "#             marker=dict(size=10, color='gold'))\n",
    "\n",
    "minimizer = go.Scatter3d(x=[w0_star], y=[w1_star], z=[mse_for_departure_model([w0_star, w1_star])], \n",
    "                         mode='markers', name='optimal parameters',\n",
    "                         marker=dict(size=10, color='gold'))\n",
    "\n",
    "fig = go.Figure(data=[loss_surface, minimizer])\n",
    "# fig.add_trace(opt_point)\n",
    "\n",
    "fig.update_layout(scene = dict(\n",
    "    xaxis_title = \"w0\",\n",
    "    yaxis_title = \"w1\",\n",
    "    zaxis_title = r\"R(w0, w1)\"))\n",
    "\n",
    "\n",
    "fig.show()\n",
    "# else:\n",
    "#     print(\"Picking num points > 100 can be really slow. If you really want to try, edit the code above so that this if statement doesn't trigger.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aside: Pitfalls of correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anscombe = pd.read_csv('data/anscombe.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "for i, n in enumerate(['I', 'II', 'III', 'IV']):\n",
    "    rows = anscombe[anscombe.get('dataset') == n]\n",
    "    x = rows['x']\n",
    "    y = rows['y']\n",
    "    \n",
    "    plt.subplot(2, 2, i+1)\n",
    "    plt.scatter(x, y, label=f'Dataset {n}', alpha=0.65, s=65)\n",
    "    plt.title(f'Dataset {n}');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do all four of these datasets have in common?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, n in enumerate(['I', 'II', 'III', 'IV']):\n",
    "    rows = anscombe[anscombe.get('dataset') == n]\n",
    "    x = rows['x']\n",
    "    y = rows['y']\n",
    "    \n",
    "    r = correlation(x, y)\n",
    "    outstr = f'''\n",
    "    <b>Dataset {n}</b><br>\n",
    "    $\\\\bar x$: {np.round(np.mean(x), 2)}<br>\n",
    "    $\\\\bar y$: {np.round(np.mean(y), 2)}<br>\n",
    "    $\\\\sigma_x$: {np.round(np.std(x), 2)}<br>\n",
    "    $\\\\sigma_y$: {np.round(np.std(y), 2)}<br>\n",
    "    $r$: {np.round(r, 2)}\n",
    "    '''\n",
    "    display(HTML(outstr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They all share the exact same mean and standard deviation of $x$ and $y$, and the same correlation coefficient $r$! This means they all have the same best linear hypothesis function, in the sense of minimizing squared loss.\n",
    "\n",
    "However, that linear hypothesis function **looks** better for some datasets than it does for others:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "for i, n in enumerate(['I', 'II', 'III', 'IV']):\n",
    "    rows = anscombe[anscombe.get('dataset') == n]\n",
    "    x = rows['x']\n",
    "    y = rows['y']\n",
    "    \n",
    "    w0_ans = intercept(x, y)\n",
    "    w1_ans = slope(x, y)\n",
    "    \n",
    "    plt.subplot(2, 2, i+1)\n",
    "    plt.scatter(x, y, label=f'Dataset {n}', alpha=0.65, s=65)\n",
    "    plt.plot(x, w0_ans + w1_ans * x, color='red');\n",
    "    plt.title(f'Dataset {n}');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moral of the story â€“ visualize your data before trying to fit a prediction rule!\n",
    "\n",
    "Another example of this phenomenon is the [Datasaurus Dozen ðŸ¦•](https://www.autodesk.com/research/publications/same-stats-different-graphs)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
