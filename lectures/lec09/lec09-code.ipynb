{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f98b8655",
   "metadata": {},
   "source": [
    "# Lecture 9 Supplementary Notebook\n",
    "\n",
    "## DSC 40A, Summer 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04088016",
   "metadata": {},
   "source": [
    "The following cell sets up the necessary imports – don't worry too much about it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "425755e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib_inline.backend_inline import set_matplotlib_formats\n",
    "set_matplotlib_formats(\"svg\")\n",
    "\n",
    "pd.options.plotting.backend = \"plotly\"\n",
    "\n",
    "# DSC 80 preferred styles\n",
    "pio.templates[\"dsc80\"] = go.layout.Template(\n",
    "    layout=dict(\n",
    "        margin=dict(l=30, r=30, t=30, b=30),\n",
    "        autosize=True,\n",
    "        xaxis=dict(showgrid=True),\n",
    "        yaxis=dict(showgrid=True),\n",
    "        title=dict(x=0.5, xanchor=\"center\"),\n",
    "    )\n",
    ")\n",
    "pio.templates.default = \"simple_white+dsc80\"\n",
    "\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1031d3",
   "metadata": {},
   "source": [
    "Let's load in the sales dataset as a `pandas` DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23af5c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/sales.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88115698",
   "metadata": {},
   "source": [
    "## Multiple Linear Regression\n",
    "\n",
    "Using our linear algebraic formulation, the optimal intercept and slope are given by the vector $\\vec{w}^*$, where:\n",
    "\n",
    "$$\\vec{w}^* = ({X^TX})^{-1} X^T\\vec{y}$$\n",
    "\n",
    "Here:\n",
    "- $X$ is a $n \\times 2$ matrix, called the **design matrix**, defined as:\n",
    "\n",
    "$${ X} = \\begin{bmatrix} { 1} & { x_1} \\\\ { 1} & { x_2} \\\\ \\vdots & \\vdots \\\\ { 1} & { x_n} \\end{bmatrix}$$\n",
    "\n",
    "- $\\vec{y}$ is a $n$-dimensional vector, called the **observation vector**, defined as:\n",
    "\n",
    "$$\\vec{y} = \\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_n \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4017589",
   "metadata": {},
   "source": [
    "### Using just one feature\n",
    "\n",
    "Before we perform multiple linear regression, let's first just perform simple linear regression. We'll try and use square footage to predict net sales; our hypothesis function will be:\n",
    "\n",
    "$$\n",
    "\\text{predicted net sales} = w_0 + w_1 \\cdot \\text{square feet}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb852057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pio.renderers.default = 'plotly_mimetype+notebook' # If the plot doesn't load for you, run this first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b29681",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(data, x='sq_ft', y='net_sales')\n",
    "fig.update_layout(xaxis_title='Square Feet', yaxis_title='Net Sales', title='Net Sales vs. Square Footage')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e60d5078",
   "metadata": {},
   "source": [
    "It seems like $w_1^*$, the optimal slope, should be positive. To find $w_0^*$ and $w_1^*$, we'll solve the normal equations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d551dbb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_normal_equations(X, y):\n",
    "    '''Returns the optimal parameter vector, w*, given a design matrix X and observation vector y.'''\n",
    "    return np.linalg.solve(X.T @ X, X.T @ y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e975046d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['1'] = 1\n",
    "\n",
    "X_one_feature_model = data[['1', 'sq_ft']]\n",
    "X_one_feature_model.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9b33e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['net_sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4875ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_one_feature_model = solve_normal_equations(X_one_feature_model, y)\n",
    "w_one_feature_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "542736d0",
   "metadata": {},
   "source": [
    "This is telling us that the best-fitting line to this dataset is\n",
    "\n",
    "$$\\text{predicted net sales} = 2.577 + 85.389 \\cdot \\text{square feet}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20326c91",
   "metadata": {},
   "source": [
    "To get predictions for all observations in my dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a8cf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_one_feature_model @ w_one_feature_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d90859",
   "metadata": {},
   "source": [
    "Let's draw a plot of our hypothesis function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef520267",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(data, x='sq_ft', y='net_sales', title='Net Sales vs. Square Feet')\n",
    "\n",
    "x_range = np.linspace(0, 10)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=data['sq_ft'], y=y, mode='markers', name='actual'))\n",
    "fig.add_trace(go.Scatter(x=x_range, \n",
    "                         y=w_one_feature_model[0] + w_one_feature_model[1] * x_range, \n",
    "                         name='Linear hypothesis Function', \n",
    "                         line=dict(color='red')))\n",
    "\n",
    "fig.update_layout(xaxis_title='Square Feet', yaxis_title='Net Sales', title='Net Sales vs. Square Footage')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37109107",
   "metadata": {},
   "source": [
    "It's also worth calculating the mean squared error of this hypothesis function, so that we can compare it to our later hypothesis functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f507a5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(X, y, w):\n",
    "    return np.mean(np.sum((y - X @ w)**2))\n",
    "\n",
    "mean_squared_error(X_one_feature_model, y, w_one_feature_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cb36fc",
   "metadata": {},
   "source": [
    "### Using two features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a22dab3",
   "metadata": {},
   "source": [
    "Let's now try to predict net sales from two variables: the square footage (size) of the store, and the number of competing stores in the area. Our model will be:\n",
    "\n",
    "$$\n",
    "\\text{predicted net sales} = w_0 + w_1 \\cdot \\text{square feet} + w_2 \\cdot \\text{competitors}\n",
    "$$\n",
    "\n",
    "Suppose $w_0^*$, $w_1^*$, and $w_2^*$ are our hypothesis function's optimal parameters. Do you expect $w_1^*$ to be positive or negative? What about $w_2^*$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00703d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(data, x='sq_ft', y='net_sales')\n",
    "fig.update_layout(xaxis_title='Square Feet', yaxis_title='Net Sales', title='Net Sales vs. Square Footage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210153a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(data, x='competing_stores', y='net_sales')\n",
    "fig.update_layout(xaxis_title='Square Feet', yaxis_title='Net Sales', title='Net Sales vs. Number of Competing Stores')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ed380e",
   "metadata": {},
   "source": [
    "Looking at separate scatter plots only tells part of the story. Let's look at a 3D scatter plot, with one axis for square footage, one axis for competing stores, and one axis for net sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e477b6e2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter3d(x=data['sq_ft'], \n",
    "                           y=data['competing_stores'], \n",
    "                           z=data['net_sales'], mode='markers'))\n",
    "\n",
    "fig.update_layout(scene=dict(\n",
    "    xaxis_title='Square Footage',\n",
    "    yaxis_title='Competing Stores',\n",
    "    zaxis_title='Net Sales'),\n",
    "    title='Net Sales vs. Square Footage and Number of Competing Stores')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d73cd5",
   "metadata": {},
   "source": [
    "Our goal is to find the best fitting **plane** to this set of points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1831b31e",
   "metadata": {},
   "source": [
    "### Question 🤔\n",
    "\n",
    "At the start of this notebook, we fit a hypothesis function with a single feature, square feet, and got that the weight of that feature was $w_1^* = 85.389$.\n",
    "\n",
    "We are about to fit a hypothesis function with two features, square feet and competing stores.\n",
    "\n",
    "**Question:** Is the weight of the square feet feature, $w_1^*$, for this **new** hypothesis function guaranteed to be equal to 85.389?\n",
    "\n",
    "A. Yes\n",
    "\n",
    "B. No"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "450f8500",
   "metadata": {},
   "source": [
    "Our design matrix is:\n",
    "    \n",
    "$$\n",
    "\\begin{pmatrix}\n",
    " 1 & s_1 & c_1\\\\\n",
    " 1 & s_2 & c_2\\\\\n",
    " \\vdots & \\vdots & \\vdots\\\\\n",
    " 1 & s_n & c_n\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "where $s_i$ is the size of the $i$th store, and $c_n$ is the number of competitors. In code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb412026",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_two_feature_model = data[['1', 'sq_ft', 'competing_stores']].to_numpy()\n",
    "X_two_feature_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfc063b",
   "metadata": {},
   "source": [
    "Using the function `solve_normal_equations` that we already built:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5f7e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_two_feature_model = solve_normal_equations(X_two_feature_model, y)\n",
    "w_two_feature_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a806b7b",
   "metadata": {},
   "source": [
    "This is telling us that the best-fitting plane to this dataset is\n",
    "\n",
    "$$\\text{predicted net sales} = 303.491 + 45.151 \\cdot \\text{square feet} - 21.585 \\cdot \\text{competing stores}$$\n",
    "\n",
    "**Note that the weight of $\\text{square feet}$ in this hypothesis function is different than the weight of $\\text{square feet}$ in the hypothesis function that only had one feature!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f69b685",
   "metadata": {},
   "outputs": [],
   "source": [
    "XX, YY = np.mgrid[-1:10:2, 0:16:2]\n",
    "Z = w_two_feature_model[0] + w_two_feature_model[1] * XX + w_two_feature_model[2] * YY\n",
    "plane = go.Surface(x=XX, y=YY, z=Z, colorscale='Reds')\n",
    "\n",
    "fig = go.Figure(data=[plane])\n",
    "fig.add_trace(go.Scatter3d(x=data['sq_ft'], \n",
    "                           y=data['competing_stores'], \n",
    "                           z=data['net_sales'], mode='markers', marker={'color': '#656DF1'}))\n",
    "\n",
    "fig.update_layout(scene=dict(\n",
    "    xaxis_title='Square Footage',\n",
    "    yaxis_title='Competing Stores',\n",
    "    zaxis_title='Net Sales'),\n",
    "    title='Net Sales vs. Square Footage and Number of Competing Stores')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b231fec",
   "metadata": {},
   "source": [
    "As before, let's calculate the MSE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90261759",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(X_two_feature_model, y, w_two_feature_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3809a3be",
   "metadata": {},
   "source": [
    "Note that this is significantly lower than the MSE of the model with just one feature:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3db456",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(X_one_feature_model, y, w_one_feature_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40d0ca7",
   "metadata": {},
   "source": [
    "### All features\n",
    "\n",
    "Let's fit a hypothesis function using all of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3757fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_order = ['1', 'sq_ft', 'competing_stores', 'inventory', 'advertising', 'district_size']\n",
    "X_all_features = data[column_order].to_numpy()\n",
    "X_all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be808d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_all_features = solve_normal_equations(X_all_features, y)\n",
    "w_all_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcf0e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, feature in enumerate(column_order):\n",
    "    if feature == '1':\n",
    "        print(f'intercept:\\t{w_all_features[0]:0.3f}')\n",
    "    else:\n",
    "        print(f'{feature}:\\t{w_all_features[i]:0.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecea1862",
   "metadata": {},
   "source": [
    "The MSE of this model is even lower!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f71da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(X_all_features, y, w_all_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d75dcc",
   "metadata": {},
   "source": [
    "Note that I can't visualize this hypothesis function, since I would need to be able to visualize in 6D, but I can still find this hypothesis function's predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6819a6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all_features @ w_all_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8492f3ab",
   "metadata": {},
   "source": [
    "## Interpreting parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59050e97",
   "metadata": {},
   "source": [
    "### Which feature is most \"important\"?\n",
    "\n",
    "We should standardize in order to account for the difference in units and scale between the features.\n",
    "\n",
    "**Question:** What would happen if I try to standardize the column of all 1s? 🧐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3238b911",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data[column_order].iloc[:, 1:].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e279c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "standardized_features = (features - features.mean(axis=0)) / features.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e049238f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_standardized = np.column_stack([\n",
    "    np.ones(data.shape[0]),\n",
    "    standardized_features\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec632c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_standardized = solve_normal_equations(X_standardized, y)\n",
    "w_standardized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969d5fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, feature in enumerate(column_order):\n",
    "    if feature == '1':\n",
    "        print(f'intercept:\\t{w_standardized[0]:0.3f}')\n",
    "    else:\n",
    "        print(f'{feature}:\\t{w_standardized[i]:0.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f6cf4e",
   "metadata": {},
   "source": [
    "The district size appears to have the largest effect on the net sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39ad6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_squared_error(X_standardized, y, w_standardized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ab4c6a",
   "metadata": {},
   "source": [
    "Note that standardizing has no impact on the actual predictions made by our hypothesis function, and hence the MSE – it just makes the weights more interpretable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73ee323",
   "metadata": {},
   "source": [
    "## Feature engineering and transformations\n",
    "\n",
    "### Example: Quadratic hypothesis functions\n",
    "\n",
    "Let's look at a new dataset of cars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367e9acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars = sns.load_dataset('mpg').dropna()\n",
    "cars.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17eb6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(cars, x='horsepower', y='mpg', title='MPG vs. Horsepower')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa840e41",
   "metadata": {},
   "source": [
    "A regular linear model here isn't great."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36609437",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars['1'] = 1\n",
    "w_cars_one_feature = solve_normal_equations(cars[['1', 'horsepower']], cars['mpg'])\n",
    "w_cars_one_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ee2616",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(cars, x='horsepower', y='mpg', title='MPG vs. Horsepower')\n",
    "\n",
    "x_range = np.linspace(40, 220)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=cars['horsepower'], y=cars['mpg'], mode='markers', name='actual'))\n",
    "fig.add_trace(go.Scatter(x=x_range, \n",
    "                         y=w_cars_one_feature[0] + w_cars_one_feature[1] * x_range, \n",
    "                         name = 'Linear Hypothesis Function', \n",
    "                         line=dict(color='red')))\n",
    "\n",
    "fig.update_layout(xaxis_title='Horsepower', yaxis_title='MPG', title='MPG vs. Horsepower')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daca3539",
   "metadata": {},
   "source": [
    "What if we add $\\text{horsepower}^2$ as a feature? This would mean fitting a hypothesis function of the form\n",
    "\n",
    "$$\\text{predicted MPG} = w_0 + w_1 \\cdot \\text{horsepower} + w_2 \\cdot \\text{horsepower}^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f9d931",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars['horsepower^2'] = cars['horsepower']**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7dba47",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars[['1', 'horsepower', 'horsepower^2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7878c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "w_cars_squared = solve_normal_equations(cars[['1', 'horsepower', 'horsepower^2']], cars['mpg'])\n",
    "w_cars_squared"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e26f584",
   "metadata": {},
   "source": [
    "Let's look at the resulting hypothesis function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74ad342",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(cars, x='horsepower', y='mpg', title='MPG vs. Horsepower')\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=cars['horsepower'], y=cars['mpg'], mode='markers', name='actual'))\n",
    "fig.add_trace(go.Scatter(x=x_range, \n",
    "                         y=w_cars_one_feature[0] + w_cars_one_feature[1] * x_range, \n",
    "                         name='Linear Hypothesis Function', \n",
    "                         line=dict(color='red')))\n",
    "fig.add_trace(go.Scatter(x=np.linspace(40, 220), \n",
    "                         y=w_cars_squared[0] + w_cars_squared[1] * x_range + w_cars_squared[2] * x_range**2, \n",
    "                         name='Quadratic Hypothesis Function', \n",
    "                         line=dict(color='#F7CF5D', width=5)))\n",
    "\n",
    "fig.update_layout(xaxis_title='Horsepower', yaxis_title='MPG', title='MPG vs. Horsepower')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7aabc98",
   "metadata": {},
   "source": [
    "Note: this hypothesis function is **quadratic as a function of horsepower**, but it's still **linear as a function of the parameters**. This means we can still use the normal equations to find $\\vec{w}^*$*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "788eef10",
   "metadata": {},
   "source": [
    "### Example: Amdahl's Law"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e454ff8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_amdahl = np.array([[1, 1],\n",
    "                     [1, 1/2],\n",
    "                     [1, 1/4]])\n",
    "\n",
    "y_amdahl = np.array([8, 4, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3f9ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "solve_normal_equations(X_amdahl, y_amdahl)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f70acbe",
   "metadata": {},
   "source": [
    "### Example: Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb092ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell generates our dataset.\n",
    "np.random.seed(28)\n",
    "x_fake = np.linspace(0, 20, 50) + np.random.normal(loc=0, scale=0.5, size=50)\n",
    "y_fake = 0.5*np.random.normal(loc=2, scale=0.5, size=50) * np.e**(0.2 * x_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2182a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(x=x_fake, y=y_fake)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55e4723",
   "metadata": {},
   "source": [
    "As per the lecture slides, we're trying to find a hypothesis function of the form\n",
    "\n",
    "$$H(x) = w_0 e^{w_1 x}$$\n",
    "\n",
    "We re-wrote this as\n",
    "\n",
    "$$\\log H(x) = \\log w_0 + w_1 x$$\n",
    "\n",
    "As a result, our design matrix $X$ is still \n",
    "\n",
    "$$X = \\begin{bmatrix}1 & x_1 \\\\ 1 & x_2 \\\\ \\vdots & \\vdots \\\\ 1 & x_n \\end{bmatrix}$$ but our observation vector is now\n",
    "\n",
    "$$\\vec{z} = \\begin{bmatrix} \\log y_1 \\\\ \\log y_2 \\\\ \\vdots \\\\ \\log y_n \\end{bmatrix}$$\n",
    "\n",
    "and our parameter vector is $$\\vec{b} = \\begin{bmatrix} b_0 \\\\ b_1 \\end{bmatrix} = \\begin{bmatrix} \\log w_0 \\\\ w_1 \\end{bmatrix}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323ebf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_trans = np.vstack([\n",
    "    np.ones_like(x_fake),\n",
    "    x_fake\n",
    "]).T\n",
    "\n",
    "z_trans = np.log(y_fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5fdca57",
   "metadata": {},
   "outputs": [],
   "source": [
    "b_trans = solve_normal_equations(X_trans, z_trans)\n",
    "b_trans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb8cd74",
   "metadata": {},
   "source": [
    "Now that we have $\\vec{b}^*$, we need to solve for $\\vec{w}^*$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf5a3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "b0, b1 = b_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd1c5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "w0_star = np.e**b0\n",
    "w1_star = b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee2dc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "w0_star, w1_star"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c33b8f",
   "metadata": {},
   "source": [
    "Let's look at a plot of the resulting hypothesis function, $H(x) = 0.965 e^{0.196 x}$, to make sure it looks reasonable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20b9174a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_range = np.arange(0, 25)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x_fake, y=y_fake, mode='markers', name='actual'))\n",
    "fig.add_trace(go.Scatter(x=x_range, \n",
    "                         y=w0_star * np.e**(w1_star * x_range), \n",
    "                         name='Exponential Hypothesis Function', \n",
    "                         line=dict(color='red')))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
