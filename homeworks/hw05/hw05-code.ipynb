{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please don't change this cell, but do make sure to run it.\n",
    "import otter\n",
    "grader = otter.Notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 5 Supplemental Notebook\n",
    "\n",
    "## DSC 40A, Summer Session 2 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "from IPython.display import Markdown\n",
    "\n",
    "pd.options.plotting.backend = \"plotly\"\n",
    "\n",
    "# DSC 40A preferred styles.\n",
    "pio.templates[\"dsc40a\"] = go.layout.Template(\n",
    "    layout=dict(\n",
    "        margin=dict(l=30, r=30, t=30, b=30),\n",
    "        autosize=True,\n",
    "        xaxis=dict(showgrid=True),\n",
    "        yaxis=dict(showgrid=True),\n",
    "        title=dict(x=0.5, xanchor=\"center\"),\n",
    "    )\n",
    ")\n",
    "pio.templates.default = \"simple_white+dsc40a\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reminder\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\" markdown=\"1\">\n",
    "\n",
    "This notebook **does not** need to be submitted! Instead, the problems that use it (Problem 4(f) and Problem 5(c)) will ask you to take screenshots of relevant pieces and include them in your Homework 5 PDF submission.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions\n",
    "\n",
    "Here, we'll define several functions that you'll need to use in this notebook. **Don't reinvent the wheel, use the functions that are here!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def solve_normal_equations(X, y):\n",
    "    '''Returns the optimal parameter vector, w*, given a design matrix X and observation vector y.'''\n",
    "    return np.linalg.solve(X.T @ X, X.T @ y)\n",
    "\n",
    "def create_design_matrix(df, columns, intercept=True):\n",
    "    '''Creates a design matrix by taking the specified columns from the DataFrame df.\n",
    "       Adds a column of all 1s as the first column if intercept is True, which is the default.\n",
    "       The argument columns should be a list.\n",
    "    '''\n",
    "    df = df.copy()\n",
    "    df['1'] = 1\n",
    "    if intercept:\n",
    "        return df[['1'] + columns].values\n",
    "    else:\n",
    "        return df[columns].values\n",
    "    \n",
    "def mean_squared_error(X, y, w):\n",
    "    '''Returns the mean squared error of the predictions Xw and observations y.'''\n",
    "    return np.mean((y - X @ w) ** 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4: Gradient Descent Gone Wrong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: test-gradient-correct\n",
    "points: 0\n",
    "-->\n",
    "\n",
    "### Problem 4(f)\n",
    "\n",
    "First, use your answers to Problem 4(d) to complete the implementations of `R`, `dR_w0`, and `dR_w1` below, given that:\n",
    "- We are trying to find the optimal parameters for the model $H(x) = w_0 + w_1 x$.\n",
    "- Our dataset has two points, $(1, 5)$ and $(2, 7)$.\n",
    "\n",
    "The function `dR` uses your implementations of `dR_w0` and `dR_w1` to find the gradient vector $\\nabla R_\\text{sq}(\\vec{w})$; you don't need to change anything within `dR`.\n",
    "\n",
    "Note that there is an autograder test cell below the following cell. This notebook isn't being graded, but that cell will verify that you implemented the necessary functions correctly, so that you can answer the rest of the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def R(w):\n",
    "    w0, w1 = w\n",
    "    ...\n",
    "    \n",
    "def dR_w0(w):\n",
    "    w0, w1 = w\n",
    "    ...\n",
    "    \n",
    "def dR_w1(w):\n",
    "    w0, w1 = w\n",
    "    ...\n",
    "    \n",
    "def dR(w):\n",
    "    # Do not change the lines below.\n",
    "    return np.array([dR_w0(w), dR_w1(w)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"test-gradient-correct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you've implemented the functions above, run the cell below to see a graph of $R_\\text{sq}(\\vec{w})$. This graph is known as a **loss surface**, and it is what we are using gradient descent to minimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points = 50\n",
    "\n",
    "uvalues = np.linspace(-1, 6, num_points)\n",
    "vvalues = np.linspace(-1, 6, num_points)\n",
    "(u,v) = np.meshgrid(uvalues, vvalues)\n",
    "thetas = np.vstack((u.flatten(),v.flatten()))\n",
    "\n",
    "MSE = np.array([R(t) for t in thetas.T])\n",
    "\n",
    "loss_surface = go.Surface(x=u, y=v, z=np.reshape(MSE, u.shape))\n",
    "\n",
    "fig = go.Figure(data=[loss_surface])\n",
    "\n",
    "fig.update_layout(scene = dict(\n",
    "    xaxis_title = \"w0\",\n",
    "    yaxis_title = \"w1\",\n",
    "    zaxis_title = r\"R(w0, w1)\"))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the function below uses `dR` to implement gradient descent. What it outputs is the same loss surface as above, along with a visualization of the **path** gradient descent took to find the minimizer, $\\vec{w}^*$. Each point corresponds to a different guess, $\\vec{w}^{(i)}$, and consecutive guesses are connected with a line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimize_R(initial, alpha):\n",
    "    w_history = []\n",
    "    risk_history = []\n",
    "    w = np.array(initial)\n",
    "    count = 0\n",
    "    \n",
    "    # The important part is here!\n",
    "    while np.linalg.norm(dR(w)) >= 0.01:\n",
    "        w_history.append(w)\n",
    "        risk_history.append(R(w))\n",
    "        w = w - alpha * dR(w)\n",
    "        count += 1\n",
    "        \n",
    "    display(Markdown(r'Best $\\vec{w}^* = [' + ','.join(w.round(3).astype(str)) + \"]^T$\"))\n",
    "    display(Markdown(f'Iterations required: {count}'))\n",
    "    # ---\n",
    "    \n",
    "    # Plot path.\n",
    "    scatter = go.Scatter3d(\n",
    "        x=[w_history[i][0] for i in range(len(risk_history))], \n",
    "        y=[w_history[i][1] for i in range(len(risk_history))], \n",
    "        z=risk_history, \n",
    "        mode=\"lines+markers\",                   \n",
    "        marker=dict(\n",
    "            symbol=\"circle\",\n",
    "            size=8)\n",
    "    )\n",
    "\n",
    "    fig2 = go.Figure(data=[fig.data[0], scatter])\n",
    "    return fig2\n",
    "    # ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"><b>Your Job</b></span>\n",
    "\n",
    "First, run the cell below. It visualizes the execution of gradient descent with $\\vec{w}^{(0)} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$ and $\\alpha = 0.1$. Then, repeatedly run the cell below, but change the values of `initial` and `alpha`. (Run it with at least 20 different combinations of arguments – what happens when you make `alpha` bigger? Smaller? What if you change `initial`?)\n",
    "\n",
    "**In your PDF**, answer the following questions:\n",
    "\n",
    "- Around what value of $\\alpha$ does gradient descent stop converging? Include a screenshot of the plot below with the largest value of $\\alpha$ you were able to successfully find $\\vec{w}^*$ with.\n",
    "- Why isn't gradient descent showing \"Best $\\vec{w}^* = [3, 2]^T$\", but instead a slightly different $\\vec{w}^*$, even though we know $w_0^* = 3$ and $w_1^* = 2$ exactly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimize_R([0, 0], 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, you do not need to submit this notebook! Instead, follow the instructions in the <span style=\"color:red\"><b>Your Job</b></span> cell above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5: Transformation Tuesday"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are two new functions – the logistic function, `sigma`, and its inverse, `sigma_inv`. Note that both functions are **vectorized**, meaning that if you give them an array as input, you will get an array back as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigma(x):\n",
    "    return 1 / (1 + np.e ** (-x))\n",
    "\n",
    "def sigma_inv(x):\n",
    "    return np.log((x / (1 - x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's load in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_data = pd.read_csv('data/logistic_data.csv')\n",
    "logistic_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a scatter plot of it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.scatter(logistic_data, x='x', y='y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5(c)\n",
    "\n",
    "In the cell below, assign `X` and `z` to the design matrix and observation vector such that `solve_normal_equations(X, z)` will give us our optimal parameter vector.\n",
    "\n",
    "_Hint: Remember that `sigma` and `sigma_inv` are vectorized, as noted above, and that we've defined `create_design_matrix` for you. Each definition should only take one line. **Don't use a `for`-loop!**_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ...\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = ...\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you answer the above two parts, you should be able to run the following two cells to see the value of $\\vec{w}^*$ and a fit version of our hypothesis function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_star_logistic = solve_normal_equations(X, z)\n",
    "w_star_logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_range = np.linspace(-11, 5)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=logistic_data['x'], y=logistic_data['y'], mode='markers', name='actual'))\n",
    "fig.add_trace(go.Scatter(x=x_range, \n",
    "                         y=sigma(w_star_logistic[0] + w_star_logistic[1] * x_range), \n",
    "                         name='Hypothesis Function', \n",
    "                         line=dict(color='red')))\n",
    "\n",
    "fig.update_layout(xaxis_title='Total Bill', yaxis_title ='Tip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, you do not have to submit this notebook! Instead, include a screenshot of the above plot in your PDF for Problem 5(c)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
