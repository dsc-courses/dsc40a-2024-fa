{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please don't change this cell, but do make sure to run it.\n",
    "import otter\n",
    "grader = otter.Notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 5 Supplemental Notebook\n",
    "\n",
    "## DSC 40A, Spring 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "from IPython.display import Markdown\n",
    "\n",
    "pd.options.plotting.backend = \"plotly\"\n",
    "\n",
    "# DSC 40A preferred styles.\n",
    "pio.templates[\"dsc40a\"] = go.layout.Template(\n",
    "    layout=dict(\n",
    "        margin=dict(l=30, r=30, t=30, b=30),\n",
    "        autosize=True,\n",
    "        xaxis=dict(showgrid=True),\n",
    "        yaxis=dict(showgrid=True),\n",
    "        title=dict(x=0.5, xanchor=\"center\"),\n",
    "    )\n",
    ")\n",
    "pio.templates.default = \"simple_white+dsc40a\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reminder\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\" markdown=\"1\">\n",
    "\n",
    "This notebook **does not** need to be submitted! Instead, the problems that use it (Problem 4(f) and Problem 5(c)) will ask you to take screenshots of relevant pieces and include them in your Homework 5 PDF submission.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4: Gradient Descent Gone Wrong"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<!--\n",
    "BEGIN QUESTION\n",
    "name: test-gradient-correct\n",
    "points: 0\n",
    "-->\n",
    "\n",
    "### Problem 4(f)\n",
    "\n",
    "First, use your answers to Problem 4(d) to complete the implementations of `R`, `dR_w0`, and `dR_w1` below, given that:\n",
    "- We are trying to find the optimal parameters for the model $H(x) = w_0 + w_1 x$.\n",
    "- Our dataset has two points, $(1, 5)$ and $(2, 7)$.\n",
    "\n",
    "The function `dR` uses your implementations of `dR_w0` and `dR_w1` to find the gradient vector $\\nabla R_\\text{sq}(\\vec{w})$; you don't need to change anything within `dR`.\n",
    "\n",
    "Note that there is an autograder test cell below the following cell. This notebook isn't being graded, but that cell will verify that you implemented the necessary functions correctly, so that you can answer the rest of the problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def R(w):\n",
    "    w0, w1 = w\n",
    "    ...\n",
    "    \n",
    "def dR_w0(w):\n",
    "    w0, w1 = w\n",
    "    ...\n",
    "    \n",
    "def dR_w1(w):\n",
    "    w0, w1 = w\n",
    "    ...\n",
    "    \n",
    "def dR(w):\n",
    "    # Do not change the lines below.\n",
    "    return np.array([dR_w0(w), dR_w1(w)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"test-gradient-correct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you've implemented the functions above, run the cell below to see a graph of $R_\\text{sq}(\\vec{w})$. This graph is known as a **loss surface**, and it is what we are using gradient descent to minimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points = 50\n",
    "\n",
    "uvalues = np.linspace(-1, 6, num_points)\n",
    "vvalues = np.linspace(-1, 6, num_points)\n",
    "(u,v) = np.meshgrid(uvalues, vvalues)\n",
    "thetas = np.vstack((u.flatten(),v.flatten()))\n",
    "\n",
    "MSE = np.array([R(t) for t in thetas.T])\n",
    "\n",
    "loss_surface = go.Surface(x=u, y=v, z=np.reshape(MSE, u.shape))\n",
    "\n",
    "fig = go.Figure(data=[loss_surface])\n",
    "\n",
    "fig.update_layout(scene = dict(\n",
    "    xaxis_title = \"w0\",\n",
    "    yaxis_title = \"w1\",\n",
    "    zaxis_title = r\"R(w0, w1)\"))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the function below uses `dR` to implement gradient descent. What it outputs is the same loss surface as above, along with a visualization of the **path** gradient descent took to find the minimizer, $\\vec{w}^*$. Each point corresponds to a different guess, $\\vec{w}^{(i)}$, and consecutive guesses are connected with a line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimize_R(initial, alpha):\n",
    "    w_history = []\n",
    "    risk_history = []\n",
    "    w = np.array(initial)\n",
    "    count = 0\n",
    "    \n",
    "    # The important part is here!\n",
    "    while np.linalg.norm(dR(w)) >= 0.01:\n",
    "        w_history.append(w)\n",
    "        risk_history.append(R(w))\n",
    "        w = w - alpha * dR(w)\n",
    "        count += 1\n",
    "        \n",
    "    display(Markdown(r'Best $\\vec{w}^* = [' + ','.join(w.round(3).astype(str)) + \"]^T$\"))\n",
    "    display(Markdown(f'Iterations required: {count}'))\n",
    "    # ---\n",
    "    \n",
    "    # Plot path.\n",
    "    scatter = go.Scatter3d(\n",
    "        x=[w_history[i][0] for i in range(len(risk_history))], \n",
    "        y=[w_history[i][1] for i in range(len(risk_history))], \n",
    "        z=risk_history, \n",
    "        mode=\"lines+markers\",                   \n",
    "        marker=dict(\n",
    "            symbol=\"circle\",\n",
    "            size=8)\n",
    "    )\n",
    "\n",
    "    fig2 = go.Figure(data=[fig.data[0], scatter])\n",
    "    return fig2\n",
    "    # ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"><b>Your Job</b></span>\n",
    "\n",
    "First, run the cell below. It visualizes the execution of gradient descent with $\\vec{w}^{(0)} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$ and $\\alpha = 0.1$. Then, repeatedly run the cell below, but change the values of `initial` and `alpha`. (Run it with at least 20 different combinations of arguments â€“ what happens when you make `alpha` bigger? Smaller? What if you change `initial`?)\n",
    "\n",
    "**In your PDF**, answer the following questions:\n",
    "\n",
    "- Around what value of $\\alpha$ does gradient descent stop converging? Include a screenshot of the plot below with the largest value of $\\alpha$ you were able to successfully find $\\vec{w}^*$ with.\n",
    "- Why isn't gradient descent showing \"Best $\\vec{w}^* = [3, 2]^T$\", but instead a slightly different $\\vec{w}^*$, even though we know $w_0^* = 3$ and $w_1^* = 2$ exactly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimize_R([0, 0], 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, you do not need to submit this notebook! Instead, follow the instructions in the <span style=\"color:red\"><b>Your Job</b></span> cell above."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
