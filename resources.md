---
layout: page
title: ðŸ“š Resources
description: Useful links and resources.
nav_order: 4
---

# ðŸ“š Resources

{:.no_toc}

## Table of contents

{: .no_toc .text-delta }

1. TOC
   {:toc}

---

## Lecture Videos

In the table below, you can find lecture videos created by Janine Tiefenbruck, who created this course and taught it many times. The lecture videos linked below will generally be pretty similar in content coverage to our lectures, but there are indeed differences in notation and order. You are responsible for everything covered in our lectures, even if something doesnâ€™t appear in the videos below. When in doubt, refer to the main lecture slides posted and ask on Ed.

| **Video**                                | **Topics**                                                  |
| ---------------------------------------- | ----------------------------------------------------------- |
| [Video 1](https://youtu.be/6tP6crJr32U)  | learning from data, mean absolute error                     |
| [Video 2](https://youtu.be/ad2S7XnCSVc)  | minimizing mean absolute error                              |
| [Video 3](https://youtu.be/LYJW_2odH_E)  | mean squared error                                          |
| [Video 4](https://youtu.be/usam2JTOaLg)  | empirical risk minimization, general framework, 0-1 loss    |
| [Video 5](https://youtu.be/Syw_PfmWDRg)  | UCSD loss                                                   |
| [Video 6](https://youtu.be/F2ImJ3dkkZ8)  | gradient descent                                            |
| [Video 7](https://youtu.be/1TjwPNY2Gzw)  | gradient descent demo, convexity                            |
| [Video 8](https://youtu.be/NdkDK3Jb6SY)  | spread                                                      |
| [Video 9](https://youtu.be/3RiaKo2jGIk)  | linear prediction rule                                      |
| [Video 10](https://youtu.be/Ac1EFASUA9M) | least squares solutions                                     |
| [Video 11](https://youtu.be/0sWcrJSAUFQ) | regression interpretation                                   |
| [Video 12](https://youtu.be/bTp4vMu_9N0) | nonlinear trends                                            |
| [Video 13](https://youtu.be/7k3KtI4NFas) | linear algebra for regression                               |
| [Video 14](https://youtu.be/2ebdHtxb4as) | gradient, normal equations                                  |
| [Video 15](https://youtu.be/uIbnLq6IZLI) | polynomial regression, nonlinear trends                     |
| [Video 16](https://youtu.be/tuezO9tiXnE) | multiple regression                                         |
| [Video 17](https://youtu.be/dDn6iPpbH4E) | k-means clustering                                          |
| [Video 18](https://youtu.be/UPxe97Wc1gM) | k-means clustering, cost function, practical considerations |
| [Video 19](https://youtu.be/ikLzykAaLOk) | probability, basic rules                                    |
| [Video 20](https://youtu.be/qHOG3yc4UzE) | conditional probability                                     |
| [Video 21](https://youtu.be/-3v6UZ_Cq9k) | probability, random sampling, sequences                     |
| [Video 22](https://youtu.be/AfM9akq6PL0) | combinatorics, sequences, sets, permutations, combinations  |
| [Video 23](https://youtu.be/fuaFj7aeg9I) | counting and probability practice                           |
| [Video 24](https://youtu.be/I3ZHwf8qWS4) | law of total probability, Bayes' Theorem                    |
| [Video 25](https://youtu.be/AUiX4gWWsuE) | independence, conditional independence                      |
| [Video 26](https://youtu.be/WLQMoA4ZAus) | naive Bayes                                                 |
| [Video 27](https://youtu.be/4tGtziW901Y) | text classification, spam filter, naive Bayes               |

---

## Course Notes

The notes for this class were written by Janine Tiefenbruck and Justin Eldridge. These notes cover the material from the first half of the course, but as of Summer 2024, the order of coverage may be different.

- [Chapter 1: Learning via Optimization](../resources/notes/notes_chapter_1.pdf)
- [Supplement on Spread](../resources/notes/spread.pdf)
- [Chapter 2: Least Squares Regression](../resources/notes/notes_chapter_2.pdf)

---

## Tutor-Created Supplemental Resources

These resources were created by tutors as part of their Final Project for DSC 95, the first-time tutor training course.

- Alan Wang's [video showing the equivalence of the various regression formulas](https://youtu.be/h2qMB1g9zSQ?si=55ziwlomsIFkC9d7).
- Brighten Hayama and Yosen Lin's [linear regression overview](https://drive.google.com/file/d/1ayBd1EdM5O4jmPgi0DtM2eWKNp5262nD/view?usp=sharing).
- Pallavi Prabhu's [permutations and combinations guide](https://drive.google.com/file/d/1v5AFjUSzeleVQBe2m2Wd27ViSUC00sY6/view?usp=sharing).
- Pranav Rebala's [conditional probability presentation](https://docs.google.com/presentation/d/1s-W4NTHwfBKBFdB1fjqDXmWPk69G0K0nse7ukfRQ2bw/edit?usp=sharing).
- Benjamin Xue's [visualizing independence guide](https://docs.google.com/document/d/e/2PACX-1vTV_h_3yrVwY5JAZ2ZIyKQ6J84t3jsHtaoEMDpduumvtWu5idmf1timb9SfrEpqMdqqkYPvpjqned8Z/pub).
- Javier Ponce's [probability guide](https://docs.google.com/presentation/d/1INFkQA6H06NEicGpzEMornQWaAwYb1zUVRPOF9nGSDw/edit?usp=sharing).
- Charlie Sun's [example midterm notes sheet](https://drive.google.com/file/d/1XRW26AeMzdvOu-LNks-4sso6e1xXcH4b/view?usp=sharing).
- Candus Shi's [slides](https://docs.google.com/presentation/d/1_SvEkGPlfel_NfSg4w-M5HvEa8UdO24l9FW4VokmuaQ/edit?usp=sharing) and [video on the importance of math as a data scientist](https://drive.google.com/file/d/1dMej66xoUzj5g10XvOn4i4fq5Ri1-HQ3/view?usp=sharing)

---

## Probability

Unlike the first half of the course, where we had course notes written specifically for this class, we don't have DSC 40A-specific notes for the second half of the class, because there are many high-quality resources available online that cover the same material. Below, you'll find links to some of these resources.

### Readings and Sources of Practice Problems

- [Open Intro Statistics](https://leanpub.com/os): Sections 2.1, 2.3, and 2.4 cover the probability we are learning in this course at a good level for undergraduates. This is a good substitute for a textbook, similar to the course notes that we had for the first part of the course. It goes through the definitions, terminology, probability rules, and how to use them. It's succinct and highlights the most important things.

- [Probability for Data Science](https://textbook.prob140.org/): Chapters 1 and 2 of this book have a lot of good examples demonstrating some standard problem-solving techniques. This book should be primarily useful for more problems to practice and learn from. This book is written at a good level for students in this class. It is used at UC Berkeley in their Probability for Data Science course. Our course only really covers material from the first two chapters, but if you want to extend your learning of probability as it applies to data science, this is a good book to help you do that.

- [Theory Meets Data](http://stat88.org/textbook/content/intro.html): Chapters 1 and 2 of this book cover similar content to Chapters 1 and 2 of the Probability for Data Science book, but with different prose and examples. It is used at UC Berkeley for a more introductory Probability for Data Science course.

- [Grinstead and Snell's Introduction to Probability](https://cse103.github.io/Resources/GrinsteadSnell.pdf): Chapters 1, 3, and 4.1 of this book cover the material from our class. This book is a lot longer and more detailed than the others, and it uses more formal mathematical notation. It should give you a very thorough understanding of probability and combinatorics, but it is a lot more detailed, so the more abbreviated resources above will likely be more useful. With that said, this book is written at a good level for undergraduates and is used in other undergraduate probability classes at UCSD, such as CSE 103.

- [Introduction to Mathematical Thinking](http://imt-decal.org): This course covers topics in discrete math, some of which are relevant to us (in particular, set theory and counting). In addition to the lecture videos linked on the homepage, you may want to look at the [notes section](http://notes.imt-decal.org).

- [Khan Academy: Counting, Permutations, and Combinations](https://www.khanacademy.org/math/statistics-probability/counting-permutations-and-combinations#combinatorics-probability): Khan Academy has a good unit called Counting, Permutations, and Combinations that should be pretty helpful for the combinatorics we are learning in this class. A useful aspect of it is the practice questions that combine permutations and combinations. Most students find that the hardest part of these counting problems is knowing when to use permutations and when to use combinations. These practice questions have them mixed together, so you really get practice learning which is the right technique to apply to which situation.

### Probability Roadmap

Janine Tiefenbruck wrote a "Probability Roadmap" that aims to guide students through the process of solving probability problems. It comes in three versions:

- [Examples](../resources/probability/Probability_Roadmap_With_Examples.pdf): This document consists of strategies followed by example problems that employ those strategies. If you're looking to gain additional practice, start here.
- [Solutions](../resources/probability/Probability_Roadmap_With_Solutions.pdf): This document contains solutions and explanations for all of the example problems in the first document. After you've attempted the problems on your own, read through this full document. Even if you've solved all the questions, you're likely to learn how to do some problems in new ways.
- [Summary](../resources/probability/Probability_Roadmap_Summary.pdf): This document is a concise summary and contains only the strategies themselves.

### Visualizations

- [Conditional probability: A Visual explanation by Victor Powell for Setosa](https://setosa.io/conditional/)
- [Seeing Theory](https://seeing-theory.brown.edu)

---

## Past Exams

Past exam problems can be found at [practice.dsc40a.com](https://practice.dsc40a.com).

<!-- Below, you'll find some exams (and in some cases, their solutions) from previous offerings of the course. You must be logged into your @ucsd.edu Google account to access these. -->

<!-- Some things to keep in mind:
- Certain offerings of the course had one midterm and others had two. Usually, Midterm 1 covered empirical risk minimization, and Midterm 2 covered probability.
- Topic coverage and ordering has changed over time, so the content in our exams won't necessarily exactly match the content of these past exams.
- Some of these exams were given as closed-book exams and others allowed the use of resources.
 -->

<!-- | Quarter | Instructor(s) | Midterm/Midterm 1 | Midterm 2 | Final |
| --- | --- | --- |
| Fall 2021 | Suraj Rampure | [Blank](https://drive.google.com/file/d/1izK0af67J0ub0keAVkO-T7piaG_PIIGF/view?usp=sharing), [Solutions](https://drive.google.com/file/d/1LjOZmJ2EiO8odPti5lPO4WzxrZ3znGb2/view?usp=sharing) | -- | [Blank](https://drive.google.com/file/d/1CeQe1_X9nBG7Lxut9nffJfICL9-FkF0o/view?usp=sharing), [Solutions](https://drive.google.com/file/d/1HQhEv6gzKlURDYLpN8bF07_n46e5IUVk/view?usp=sharing) |
| Spring 2021 | Janine Tiefenbruck | [Blank](https://drive.google.com/file/d/159JnzNtjw0okeucxBXmunU9u_H2ka2sa/view?usp=sharing), [Solutions](https://drive.google.com/file/d/1XZyNNI5bHM0QjkmdVm5XhqcGpKliaRgO/view?usp=sharing), [**Videos ðŸŽ¬**](https://www.youtube.com/playlist?list=PLDNbnocpJUhbNgdRB1D82Vn-BWWw7Fj6O) | -- | Part 1: [Blank](https://drive.google.com/file/d/1-J48ZsXeipJ_MQppCUWj0djafmMVC1nz/view?usp=sharing), [Solutions](https://drive.google.com/file/d/18-JfCPXTVMBqOpbEqtgFTh45erm97cV5/view?usp=sharing) |
| Winter 2021 | Gal Mishne | [Blank](https://drive.google.com/file/d/13MMQfqO11QiXjfEkFh3Ftua2U205GyVG/view?usp=sharing), [Solutions](https://drive.google.com/file/d/1EymkLTxyTTA7LzeWArWIwlYi5Frt1Brm/view?usp=sharing) | [Blank](https://drive.google.com/file/d/1sXDFx1chSvEo-2IujX04entAtWRdEssz/view?usp=sharing), [Solutions](https://drive.google.com/file/d/1ZumQumC0XS-nFbjyhx3Ol1WFITFnJgMT/view?usp=sharing) | Part 1: [Solutions](https://drive.google.com/file/d/1ptFdOOMKJ0dJxtX8Fg5otHdeyMuQhT3f/view?usp=sharing) <br> Part 2: [Solutions](https://drive.google.com/file/d/1VBqzXtnWGhSwMBU-ydXtfZZdde2wDzNt/view?usp=sharing) |
| Fall 2020 | Janine Tiefenbruck, Yian Ma | [Blank](https://drive.google.com/file/d/1n_yvPUyGfp9p6406FXrTD52xc_Tctykv/view?usp=sharing), [Solutions](https://drive.google.com/file/d/1sOFCym0FrMF7ZCf_Q6Gz3icF8iIdlkPt/view?usp=sharing) | -- | Part 1: [Blank](https://drive.google.com/file/d/1xx0ovIBlmlNM2Jls6CIcyxsIYcwBNdic/view?usp=sharing), [Solutions](https://drive.google.com/file/d/1jbIO2xz0MMSTs1VUlu07yiNJYrMRU8Np/view?usp=sharing) |
| Spring 2020 | Janine Tiefenbruck | [Blank](https://drive.google.com/file/d/1rORHtb7uw9hsYec-2LWwKMh3ikEaxVVf/view?usp=sharing), [**Videos ðŸŽ¬**](https://www.youtube.com/playlist?list=PLDNbnocpJUhZPkdrIW984vwcTAdEX0Lam) | -- | Part 1: [Blank](https://drive.google.com/file/d/1LPnysH4z6aadrJPqwSXtk_APs1jaXMr3/view?usp=sharing) |
| Winter 2020 | Justin Eldridge | [Solutions](https://drive.google.com/file/d/1-eQjRyfl-v8IkLuvJYnYTdtw0T72I87C/view?usp=sharing) | [Solutions](https://drive.google.com/file/d/1cIq2W52LJVrNbC4hnL1oeU4JtyOpwCIW/view?usp=sharing) | [Solutions](https://drive.google.com/file/d/17_ITSLkzNdJhWezBqJsORhiaViIWW6aV/view?usp=sharing) | -->

---

## Other Resources

- Other lectures on [Loss Functions](http://ds100.org/su20/lecture/lec11) and [Simple Linear Regression](http://ds100.org/su20/lecture/lec12/).
  - These are from a different course for a different audience, and use different notation and terminology. However, the high-level ideas are similar to those in the first few weeks of our course.
- [Gradient Descent visualizer](https://uclaacm.github.io/gradient-descent-visualiser/#playground).
- Notes on [Convexity](https://sboyles.github.io/teaching/ce377k/convexity.pdf) by Stephen Boyles.

If you find another helpful resource, let us know and we can link it here!
